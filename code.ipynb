{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "dataset = pd.read_excel(\"recruitment.xls\")\n",
    "\n",
    "# replace all NaN values with 0 (this is consistent with the answers in the dataset)\n",
    "dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender-OfferNY chi-square test results:\n",
      "Test statistic = 20.543285097740544\n",
      "p-value = 5.829793346746857e-06\n",
      "\n",
      "BAMEyn-OfferNY chi-square test results:\n",
      "Test statistic = 2.718321003055136\n",
      "p-value = 0.09920231543819825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "# perform and output the results of a chi-squared independence test between two attributes from the data\n",
    "def perform_x2_test(dataset, attribute1, attribute2):\n",
    "    \n",
    "    N = dataset.shape[0]\n",
    "    \n",
    "    n1 = dataset[dataset[attribute1] == 2][attribute2].value_counts()[1]\n",
    "    n2 = dataset[dataset[attribute1] == 2][attribute2].value_counts()[0]\n",
    "    n3 = dataset[dataset[attribute1] == 1][attribute2].value_counts()[1]\n",
    "    n4 = dataset[dataset[attribute1] == 1][attribute2].value_counts()[0]\n",
    "    \n",
    "    e1 = (n3 + n1) * (n1 + n2) / N\n",
    "    e2 = (n4 + n2) * (n1 + n2) / N\n",
    "    e3 = (n3 + n1) * (n3 + n4) / N\n",
    "    e4 = (n4 + n2) * (n3 + n4) / N\n",
    "    \n",
    "    observed = [n1, n2, n3, n4]\n",
    "    expected = [e1, e2, e3, e4]\n",
    "    \n",
    "    chi_sq_val, p_val = chisquare(observed, expected, ddof=2)\n",
    "    \n",
    "    print(attribute1 + \"-\" + attribute2 + \" chi-square test results:\\nTest statistic = \" + str(chi_sq_val) + \"\\np-value = \" + str(p_val) + \"\\n\")\n",
    "\n",
    "# output results of chi-squared independence test between Gender and OfferNY, and BAMEyn and OfferNY\n",
    "perform_x2_test(dataset, \"Gender\", \"OfferNY\")\n",
    "perform_x2_test(dataset, \"BAMEyn\", \"OfferNY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of males shortlisted for interview = 48.717948717948715\n",
      "Percentage of females shortlisted for interview = 24.752475247524753\n",
      "Percentage of males invited to interview = 34.61538461538461\n",
      "Percentage of females invited to interview = 13.861386138613863\n",
      "Percentage of males offered a job = 23.076923076923077\n",
      "Percentage of females offered a job = 4.9504950495049505\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "male_dataset = dataset[dataset[\"Gender\"] == 1]\n",
    "female_dataset = dataset[dataset[\"Gender\"] == 2]\n",
    "\n",
    "print(\"Percentage of males shortlisted for interview = \" + str(100*np.mean(male_dataset[\"ShortlistedNY\"])))\n",
    "print(\"Percentage of females shortlisted for interview = \" + str(100*np.mean(female_dataset[\"ShortlistedNY\"])))\n",
    "print(\"Percentage of males invited to interview = \" + str(100*np.mean(male_dataset[\"Interviewed\"])))\n",
    "print(\"Percentage of females invited to interview = \" + str(100*np.mean(female_dataset[\"Interviewed\"])))\n",
    "print(\"Percentage of males offered a job = \" + str(100*np.mean(male_dataset[\"OfferNY\"])))\n",
    "print(\"Percentage of females offered a job = \" + str(100*np.mean(female_dataset[\"OfferNY\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender-ShortlistedNY chi-square test results:\n",
      "Test statistic = 14.996576580734997\n",
      "p-value = 0.00010770639139776792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_x2_test(dataset, \"Gender\", \"ShortlistedNY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# class implementing logistic regression\n",
    "class LogReg:\n",
    "    \n",
    "    # initialize LogReg object, setting maximum number of iterations and initializing coefficients\n",
    "    def __init__(self, max_iter=1000):\n",
    "        self.max_iter = max_iter\n",
    "        self.coefs = None\n",
    "    \n",
    "    # train the model, using gradient descent to find the optimal coefficients within the number of iterations\n",
    "    def fit(self, X, y, learn_rate=0.3):\n",
    "        self.coefs = np.zeros(X.shape[1] + 1, dtype=np.float32)\n",
    "        N = X.shape[0]\n",
    "        for t in range(self.max_iter):\n",
    "            g = np.zeros(X.shape[1] + 1, dtype=np.float32) # gradient vector\n",
    "            sigmoid = self.compute_sigmoid(X)\n",
    "            loss = np.array(y) - sigmoid\n",
    "            g[0] = np.sum(-1 * loss)\n",
    "            k = 1\n",
    "            for col in X.columns:\n",
    "                g[k] = np.sum(-1 * loss * np.array(X[col]))\n",
    "                k += 1\n",
    "                \n",
    "            self.coefs -= (learn_rate / N) * g # update coefficients simultaneously with respect to gradient\n",
    "     \n",
    "    # compute the sigmoid function for either a set of individuals, or one individual\n",
    "    def compute_sigmoid(self, X):\n",
    "        l = np.full(X.shape[0], self.coefs[0], dtype=np.float32)\n",
    "        \n",
    "        k = 1\n",
    "        for col in X.columns:\n",
    "            l += self.coefs[k] * np.array(X[col])\n",
    "            k += 1\n",
    "            \n",
    "        return 1 / (1 + np.exp(-1 * l))\n",
    "    \n",
    "    # predict class labels for either a set of individuals, or one individual\n",
    "    def predict(self, X, include_proba=False):\n",
    "        sigmoid = self.compute_sigmoid(X)\n",
    "        y_pred = np.where(sigmoid > 0.5, 1, 0)\n",
    "        if include_proba is False:\n",
    "            return y_pred\n",
    "        else:            \n",
    "            return y_pred, sigmoid\n",
    "\n",
    "# columns for X variables\n",
    "X_columns = [\"Gender\", \"BAMEyn\", \"ShortlistedNY\", \"Interviewed\", \"FemaleONpanel\"]\n",
    "\n",
    "# get X and y\n",
    "X = dataset[X_columns]\n",
    "y = dataset[\"OfferNY\"]\n",
    "\n",
    "# perform a random 70/30 train-test split on X and y. The split will be the same each time due to random_state=10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=10)\n",
    "\n",
    "# create a LogReg object and fit it to the training data\n",
    "lr = LogReg()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male test set individuals = 20\n",
      "Male accuracy score = 0.85\n",
      "Male f1 score = 0.6666666666666665\n",
      "Male precision score = 0.75\n",
      "Male recall score = 0.6\n",
      "Male % predicted 1 = 20.0\n",
      "\n",
      "Female test set individuals = 64\n",
      "Female accuracy score = 0.90625\n",
      "Female f1 score = 0.25\n",
      "Female precision score = 1.0\n",
      "Female recall score = 0.14285714285714285\n",
      "Female % predicted 1 = 1.5625\n",
      "\n",
      "Overall test set individuals = 84\n",
      "Overall accuracy score = 0.8928571428571429\n",
      "Overall f1 score = 0.47058823529411764\n",
      "Overall precision score = 0.8\n",
      "Overall recall score = 0.3333333333333333\n",
      "Overall % predicted 1 = 5.9523809523809526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display accuracy and bias metrics for a given classifier and test set\n",
    "def display_metrics(classifier, X_test, y_test, label):    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(label + \" test set individuals = \" + str(len(y_test)))\n",
    "    print(label + \" accuracy score = \" + str(accuracy_score(y_test, y_pred)))\n",
    "    print(label + \" f1 score = \" + str(f1_score(y_test, y_pred)))\n",
    "    print(label + \" precision score = \" + str(precision_score(y_test, y_pred)))\n",
    "    print(label + \" recall score = \" + str(recall_score(y_test, y_pred)))\n",
    "    print(label + \" % predicted 1 = \" + str(100 * np.sum(y_pred) / len(y_pred)) + \"\\n\")\n",
    "\n",
    "# split test set into male and female test sets\n",
    "X_test_male = X_test[X_test[\"Gender\"] == 1]\n",
    "y_test_male = y_test.values[np.where(X_test[\"Gender\"] == 1)]\n",
    "X_test_female = X_test[X_test[\"Gender\"] == 2]\n",
    "y_test_female = y_test.values[np.where(X_test[\"Gender\"] == 2)]\n",
    "\n",
    "# display accuracy metrics for males and females, and overall (on test sets)\n",
    "display_metrics(lr, X_test_male, y_test_male, \"Male\")\n",
    "display_metrics(lr, X_test_female, y_test_female, \"Female\")\n",
    "display_metrics(lr, X_test, y_test, \"Overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robbi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# class implementing logistic regression with an adversarial component to mitigate bias. Child class of LogReg()\n",
    "class AdvLogReg(LogReg):\n",
    "    \n",
    "    # initialize LogReg object, setting maximum number of iterations and initializing coefficients\n",
    "    def __init__(self, max_iter=1000):\n",
    "        LogReg.__init__(self, max_iter)\n",
    "        self.coefs = None\n",
    "        self.adv_coefs = None\n",
    "    \n",
    "    # train the model using gradient descent, also implementing an adversary model that tries to predict the sensitive attribute\n",
    "    # of gender, based on the predicted label (by definition, this adversary tries to enforce demographic parity)\n",
    "    def fit(self, X, y, learn_rate=0.3, weights=[]):\n",
    "        # give all individuals unit weight if weights are not specified\n",
    "        if len(weights) == 0:\n",
    "            weights = np.ones(X.shape[0], dtype=np.int8)\n",
    "        self.coefs = np.zeros(X.shape[1] + 1, dtype=np.float32)\n",
    "        self.adv_coefs = np.zeros(2, dtype=np.float32)\n",
    "        N = X.shape[0]\n",
    "        for t in range(1, self.max_iter + 1):\n",
    "            g = np.zeros(X.shape[1] + 1, dtype=np.float32) # gradient vector with respect to the loss of the predictor\n",
    "            h = np.zeros(X.shape[1] + 1, dtype=np.float32) # gradient vector with respect to the loss of the adversary\n",
    "            \n",
    "            y_sigmoid = self.compute_sigmoid(X)\n",
    "            y_loss = np.array(y) - y_sigmoid\n",
    "            \n",
    "            # train adversary and update its coefficients\n",
    "            y_pred = np.where(y_sigmoid > 0.5, 1, 0) # predicted labels from y_sigmoid\n",
    "            z_sigmoid = self.compute_adv_sigmoid(y_pred)\n",
    "            z_loss = np.array(X[\"Gender\"], dtype=np.float32) - 1 - z_sigmoid           \n",
    "            self.adv_coefs[0] -= (learn_rate / N) * np.sum(-1 * z_loss)\n",
    "            self.adv_coefs[1] -= (learn_rate / N) * np.sum(-1 * z_loss * y_pred)\n",
    "            \n",
    "            # update gradient of intercepts\n",
    "            g[0] = np.sum(-1 * y_loss)\n",
    "            h[0] = np.sum(-1 * z_loss)\n",
    "            \n",
    "            # update gradient of other coefficients\n",
    "            k = 1\n",
    "            for col in X.columns:\n",
    "                g[k] = np.sum(-1 * y_loss * np.array(X[col]) * weights)\n",
    "                h[k] = np.sum(-1 * z_loss * np.array(X[col]))\n",
    "                k += 1          \n",
    "            \n",
    "            # hyperparameter alpha, changes over time, based on paper by Zhange\n",
    "            alpha = np.sqrt(1 / t)\n",
    "            \n",
    "            # update coefficients as in paper by Zhange\n",
    "            self.coefs -= (learn_rate / N) * (g - vector_project(g, h) - alpha * h)\n",
    "            \n",
    "    # compute sigmoid function for the adversary\n",
    "    def compute_adv_sigmoid(self, y_pred):\n",
    "        z_sigmoid = self.adv_coefs[0] + self.adv_coefs[1] * y_pred\n",
    "        return 1 / (1 + np.exp(-1 * z_sigmoid))\n",
    "\n",
    "# compute the projection of vector u onto vector v    \n",
    "def vector_project(u, v):\n",
    "    return (np.dot(u, v)/np.dot(v, v))*v\n",
    "\n",
    "# get sample weights for the training set, based on the definition of demographic parity\n",
    "def get_sample_weights(X_train, y_train):\n",
    "    data = X_train\n",
    "    data.insert(0, \"OfferNY\", y_train)\n",
    "    N = X_train.shape[0]\n",
    "    weights = list()\n",
    "    for i in data.index:\n",
    "        gender = data.at[i, \"Gender\"]\n",
    "        p_gender = data[\"Gender\"].value_counts()[gender] / N\n",
    "        label = data.at[i, \"OfferNY\"]\n",
    "        p_label = data[\"OfferNY\"].value_counts()[label] / N\n",
    "        p_exp = p_gender * p_label\n",
    "        p_obs = len(data[(data[\"Gender\"] == gender) & (data[\"OfferNY\"] == label)]) / N\n",
    "        weights.append(p_exp / p_obs)\n",
    "    data.drop(columns=\"OfferNY\", inplace=True)\n",
    "    return np.array(weights, dtype=np.float32)\n",
    "\n",
    "# compute the sample weights for the training set \n",
    "weights = get_sample_weights(X_train, y_train)\n",
    "\n",
    "# initialize an AdvLogReg() object, and fit the training data to it, using the sample weights above\n",
    "adv_lr = AdvLogReg()\n",
    "adv_lr.fit(X_train, y_train, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male test set individuals = 20\n",
      "Male accuracy score = 0.85\n",
      "Male f1 score = 0.6666666666666665\n",
      "Male precision score = 0.75\n",
      "Male recall score = 0.6\n",
      "Male % predicted 1 = 20.0\n",
      "\n",
      "Female test set individuals = 64\n",
      "Female accuracy score = 0.9375\n",
      "Female f1 score = 0.7142857142857143\n",
      "Female precision score = 0.7142857142857143\n",
      "Female recall score = 0.7142857142857143\n",
      "Female % predicted 1 = 10.9375\n",
      "\n",
      "Overall test set individuals = 84\n",
      "Overall accuracy score = 0.9166666666666666\n",
      "Overall f1 score = 0.6956521739130435\n",
      "Overall precision score = 0.7272727272727273\n",
      "Overall recall score = 0.6666666666666666\n",
      "Overall % predicted 1 = 13.095238095238095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_metrics(adv_lr, X_test_male, y_test_male, \"Male\")\n",
    "display_metrics(adv_lr, X_test_female, y_test_female, \"Female\")\n",
    "display_metrics(adv_lr, X_test, y_test, \"Overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIR before fairness implementation = 0.078125\n",
      "AIR after fairness implementation = 0.546875\n"
     ]
    }
   ],
   "source": [
    "# get predictions for male and female test sets for both models\n",
    "y_pred_male_reg = lr.predict(X_test_male)\n",
    "y_pred_female_reg = lr.predict(X_test_female)\n",
    "y_pred_male_fair = adv_lr.predict(X_test_male)\n",
    "y_pred_female_fair = adv_lr.predict(X_test_female)\n",
    "\n",
    "# calculate adverse impact ratio before fairness implementation and after\n",
    "air_before = (np.sum(y_pred_female_reg) / len(y_pred_female_reg)) / (np.sum(y_pred_male_reg) / len(y_pred_male_reg))\n",
    "air_after = (np.sum(y_pred_female_fair) / len(y_pred_female_fair)) / (np.sum(y_pred_male_fair) / len(y_pred_male_fair))\n",
    "\n",
    "print(\"AIR before fairness implementation =\", air_before)\n",
    "print(\"AIR after fairness implementation =\", air_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
